{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyORoi0DJMU29G7uQ3rwyVdp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shivasky18/DL_ASSIGNMENT_1/blob/main/DL_ASSIGNMENT_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Download the MNIST Dataset and Plot Sample Images for Each Class"
      ],
      "metadata": {
        "id": "RkJ-Eua4wigL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "def plot_sample_images(x_train, y_train):\n",
        "    fig, axes = plt.subplots(2, 5, figsize=(10, 5))\n",
        "    axes = axes.ravel()\n",
        "    for i in range(10):\n",
        "        idx = np.where(y_train == i)[0][0]\n",
        "        axes[i].imshow(x_train[idx], cmap='gray')\n",
        "        axes[i].set_title(f'Label: {i}')\n",
        "        axes[i].axis('off')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_sample_images(x_train, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "YjCAUYNdwqoF",
        "outputId": "2ca261d3-ce84-4ad0-be61-a6bb97bd4781"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feedforward Neural Network"
      ],
      "metadata": {
        "id": "C5pXwRgMxE7s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Dropout\n",
        "from keras.optimizers import SGD, Adam, RMSprop\n",
        "\n",
        "def build_model(input_shape, num_hidden_layers=3, neurons_per_layer=64, activation='relu', optimizer='adam', dropout_rate=0.0):\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Flatten(input_shape=input_shape))\n",
        "\n",
        "    for _ in range(num_hidden_layers):\n",
        "        model.add(Dense(neurons_per_layer, activation=activation))\n",
        "        if dropout_rate > 0:\n",
        "            model.add(Dropout(dropout_rate))\n",
        "\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    if optimizer == 'sgd':\n",
        "        opt = SGD()\n",
        "    elif optimizer == 'adam':\n",
        "        opt = Adam()\n",
        "    elif optimizer == 'rmsprop':\n",
        "        opt = RMSprop()\n",
        "\n",
        "    model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "vapCeGlixJCU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Experiment with Different Hyperparameters"
      ],
      "metadata": {
        "id": "-9CnKEb8xpx5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1, random_state=42)\n",
        "\n",
        "def train_model(model, x_train, y_train, x_val, y_val, batch_size=32, epochs=5):\n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=3)\n",
        "    history = model.fit(x_train, y_train, validation_data=(x_val, y_val), batch_size=batch_size, epochs=epochs, callbacks=[early_stop])\n",
        "    return history\n",
        "\n",
        "model = build_model(input_shape=(28, 28), num_hidden_layers=3, neurons_per_layer=64, optimizer='adam')\n",
        "history = train_model(model, x_train, y_train, x_val, y_val, batch_size=32, epochs=10)\n"
      ],
      "metadata": {
        "id": "gpds2WF1xx18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43c661cd-c337-45ea-c78b-afa976b0f241"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8490 - loss: 0.5122 - val_accuracy: 0.9532 - val_loss: 0.1398\n",
            "Epoch 2/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9591 - loss: 0.1316 - val_accuracy: 0.9640 - val_loss: 0.1148\n",
            "Epoch 3/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9712 - loss: 0.0959 - val_accuracy: 0.9653 - val_loss: 0.1100\n",
            "Epoch 4/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9770 - loss: 0.0738 - val_accuracy: 0.9703 - val_loss: 0.0992\n",
            "Epoch 5/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9802 - loss: 0.0627 - val_accuracy: 0.9700 - val_loss: 0.0999\n",
            "Epoch 6/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9828 - loss: 0.0531 - val_accuracy: 0.9748 - val_loss: 0.0821\n",
            "Epoch 7/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9871 - loss: 0.0408 - val_accuracy: 0.9717 - val_loss: 0.1051\n",
            "Epoch 8/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9881 - loss: 0.0362 - val_accuracy: 0.9713 - val_loss: 0.1004\n",
            "Epoch 9/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9892 - loss: 0.0335 - val_accuracy: 0.9790 - val_loss: 0.0900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs_list = [3, 5]\n",
        "hidden_layers_list = [3, 5]\n",
        "neurons_list = [64, 128]\n",
        "batch_size_list = [16, 32]\n",
        "optimizers = ['sgd', 'adam', 'rmsprop']\n",
        "activation_functions = ['relu', 'sigmoid']\n",
        "\n",
        "best_accuracy = 0\n",
        "best_model = None\n",
        "best_config = {}\n",
        "\n",
        "for epochs in epochs_list:\n",
        "    for num_layers in hidden_layers_list:\n",
        "        for neurons in neurons_list:\n",
        "            for batch_size in batch_size_list:\n",
        "                for optimizer in optimizers:\n",
        "                    for activation in activation_functions:\n",
        "                        print(f\"Training with: {epochs} epochs, {num_layers} layers, {neurons} neurons, {batch_size} batch size, {optimizer} optimizer, {activation} activation\")\n",
        "                        model = build_model(input_shape=(28, 28), num_hidden_layers=num_layers, neurons_per_layer=neurons, optimizer=optimizer, activation=activation)\n",
        "                        history = train_model(model, x_train, y_train, x_val, y_val, batch_size=batch_size, epochs=epochs)\n",
        "\n",
        "                        val_acc = max(history.history['val_accuracy'])\n",
        "                        if val_acc > best_accuracy:\n",
        "                            best_accuracy = val_acc\n",
        "                            best_model = model\n",
        "                            best_config = {'epochs': epochs, 'num_layers': num_layers, 'neurons' : neurons, 'batch_size': batch_size, 'optimizer': optimizer, 'activation': activation}\n",
        "\n",
        "print(f\"Best model config: {best_config} with validation accuracy: {best_accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxwyvPpbyVze",
        "outputId": "8d53b37e-6414-47e6-e242-651db5c2b528"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with: 3 epochs, 3 layers, 64 neurons, 16 batch size, sgd optimizer, relu activation\n",
            "Epoch 1/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.7087 - loss: 0.9805 - val_accuracy: 0.9237 - val_loss: 0.2734\n",
            "Epoch 2/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9244 - loss: 0.2555 - val_accuracy: 0.9435 - val_loss: 0.1957\n",
            "Epoch 3/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9461 - loss: 0.1879 - val_accuracy: 0.9488 - val_loss: 0.1732\n",
            "Training with: 3 epochs, 3 layers, 64 neurons, 16 batch size, sgd optimizer, sigmoid activation\n",
            "Epoch 1/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.1157 - loss: 2.3030 - val_accuracy: 0.1183 - val_loss: 2.2824\n",
            "Epoch 2/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.1853 - loss: 2.2705 - val_accuracy: 0.4000 - val_loss: 2.1927\n",
            "Epoch 3/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.4003 - loss: 2.0905 - val_accuracy: 0.4993 - val_loss: 1.6048\n",
            "Training with: 3 epochs, 3 layers, 64 neurons, 16 batch size, adam optimizer, relu activation\n",
            "Epoch 1/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.8617 - loss: 0.4448 - val_accuracy: 0.9643 - val_loss: 0.1246\n",
            "Epoch 2/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - accuracy: 0.9604 - loss: 0.1260 - val_accuracy: 0.9632 - val_loss: 0.1222\n",
            "Epoch 3/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9727 - loss: 0.0893 - val_accuracy: 0.9738 - val_loss: 0.0955\n",
            "Training with: 3 epochs, 3 layers, 64 neurons, 16 batch size, adam optimizer, sigmoid activation\n",
            "Epoch 1/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.7056 - loss: 0.9933 - val_accuracy: 0.9350 - val_loss: 0.2198\n",
            "Epoch 2/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.9420 - loss: 0.1989 - val_accuracy: 0.9518 - val_loss: 0.1596\n",
            "Epoch 3/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9620 - loss: 0.1317 - val_accuracy: 0.9612 - val_loss: 0.1300\n",
            "Training with: 3 epochs, 3 layers, 64 neurons, 16 batch size, rmsprop optimizer, relu activation\n",
            "Epoch 1/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8691 - loss: 0.4341 - val_accuracy: 0.9547 - val_loss: 0.1484\n",
            "Epoch 2/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9602 - loss: 0.1344 - val_accuracy: 0.9628 - val_loss: 0.1370\n",
            "Epoch 3/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9696 - loss: 0.1085 - val_accuracy: 0.9683 - val_loss: 0.1212\n",
            "Training with: 3 epochs, 3 layers, 64 neurons, 16 batch size, rmsprop optimizer, sigmoid activation\n",
            "Epoch 1/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.6919 - loss: 1.0261 - val_accuracy: 0.9295 - val_loss: 0.2367\n",
            "Epoch 2/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9352 - loss: 0.2279 - val_accuracy: 0.9477 - val_loss: 0.1727\n",
            "Epoch 3/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9528 - loss: 0.1570 - val_accuracy: 0.9580 - val_loss: 0.1384\n",
            "Training with: 3 epochs, 3 layers, 64 neurons, 32 batch size, sgd optimizer, relu activation\n",
            "Epoch 1/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5890 - loss: 1.3624 - val_accuracy: 0.9032 - val_loss: 0.3346\n",
            "Epoch 2/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9066 - loss: 0.3193 - val_accuracy: 0.9260 - val_loss: 0.2585\n",
            "Epoch 3/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9254 - loss: 0.2538 - val_accuracy: 0.9377 - val_loss: 0.2155\n",
            "Training with: 3 epochs, 3 layers, 64 neurons, 32 batch size, sgd optimizer, sigmoid activation\n",
            "Epoch 1/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.1095 - loss: 2.3258 - val_accuracy: 0.1090 - val_loss: 2.2951\n",
            "Epoch 2/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.1274 - loss: 2.2919 - val_accuracy: 0.1090 - val_loss: 2.2838\n",
            "Epoch 3/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.1480 - loss: 2.2793 - val_accuracy: 0.1188 - val_loss: 2.2637\n",
            "Training with: 3 epochs, 3 layers, 64 neurons, 32 batch size, adam optimizer, relu activation\n",
            "Epoch 1/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8508 - loss: 0.5034 - val_accuracy: 0.9555 - val_loss: 0.1434\n",
            "Epoch 2/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9593 - loss: 0.1345 - val_accuracy: 0.9650 - val_loss: 0.1147\n",
            "Epoch 3/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9714 - loss: 0.0930 - val_accuracy: 0.9675 - val_loss: 0.1047\n",
            "Training with: 3 epochs, 3 layers, 64 neurons, 32 batch size, adam optimizer, sigmoid activation\n",
            "Epoch 1/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.6622 - loss: 1.1940 - val_accuracy: 0.9237 - val_loss: 0.2780\n",
            "Epoch 2/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9311 - loss: 0.2492 - val_accuracy: 0.9490 - val_loss: 0.1794\n",
            "Epoch 3/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9519 - loss: 0.1675 - val_accuracy: 0.9582 - val_loss: 0.1419\n",
            "Training with: 3 epochs, 3 layers, 64 neurons, 32 batch size, rmsprop optimizer, relu activation\n",
            "Epoch 1/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8565 - loss: 0.4807 - val_accuracy: 0.9477 - val_loss: 0.1770\n",
            "Epoch 2/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9572 - loss: 0.1439 - val_accuracy: 0.9632 - val_loss: 0.1291\n",
            "Epoch 3/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9696 - loss: 0.1050 - val_accuracy: 0.9682 - val_loss: 0.1104\n",
            "Training with: 3 epochs, 3 layers, 64 neurons, 32 batch size, rmsprop optimizer, sigmoid activation\n",
            "Epoch 1/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.6372 - loss: 1.2548 - val_accuracy: 0.9153 - val_loss: 0.2871\n",
            "Epoch 2/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9236 - loss: 0.2627 - val_accuracy: 0.9397 - val_loss: 0.1928\n",
            "Epoch 3/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9456 - loss: 0.1840 - val_accuracy: 0.9532 - val_loss: 0.1541\n",
            "Training with: 3 epochs, 3 layers, 128 neurons, 16 batch size, sgd optimizer, relu activation\n",
            "Epoch 1/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.7333 - loss: 0.9243 - val_accuracy: 0.9217 - val_loss: 0.2570\n",
            "Epoch 2/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9318 - loss: 0.2327 - val_accuracy: 0.9508 - val_loss: 0.1749\n",
            "Epoch 3/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9514 - loss: 0.1648 - val_accuracy: 0.9598 - val_loss: 0.1376\n",
            "Training with: 3 epochs, 3 layers, 128 neurons, 16 batch size, sgd optimizer, sigmoid activation\n",
            "Epoch 1/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.1142 - loss: 2.3055 - val_accuracy: 0.0967 - val_loss: 2.2868\n",
            "Epoch 2/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.1786 - loss: 2.2678 - val_accuracy: 0.3710 - val_loss: 2.1726\n",
            "Epoch 3/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.3890 - loss: 2.0483 - val_accuracy: 0.4837 - val_loss: 1.4694\n",
            "Training with: 3 epochs, 3 layers, 128 neurons, 16 batch size, adam optimizer, relu activation\n",
            "Epoch 1/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.8834 - loss: 0.3812 - val_accuracy: 0.9590 - val_loss: 0.1350\n",
            "Epoch 2/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.9684 - loss: 0.1047 - val_accuracy: 0.9560 - val_loss: 0.1317\n",
            "Epoch 3/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.9775 - loss: 0.0724 - val_accuracy: 0.9693 - val_loss: 0.1022\n",
            "Training with: 3 epochs, 3 layers, 128 neurons, 16 batch size, adam optimizer, sigmoid activation\n",
            "Epoch 1/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.7531 - loss: 0.7871 - val_accuracy: 0.9443 - val_loss: 0.1984\n",
            "Epoch 2/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.9519 - loss: 0.1622 - val_accuracy: 0.9628 - val_loss: 0.1189\n",
            "Epoch 3/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9674 - loss: 0.1058 - val_accuracy: 0.9677 - val_loss: 0.1032\n",
            "Training with: 3 epochs, 3 layers, 128 neurons, 16 batch size, rmsprop optimizer, relu activation\n",
            "Epoch 1/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.8841 - loss: 0.3814 - val_accuracy: 0.9640 - val_loss: 0.1238\n",
            "Epoch 2/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.9649 - loss: 0.1285 - val_accuracy: 0.9708 - val_loss: 0.1122\n",
            "Epoch 3/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.9744 - loss: 0.1017 - val_accuracy: 0.9688 - val_loss: 0.1430\n",
            "Training with: 3 epochs, 3 layers, 128 neurons, 16 batch size, rmsprop optimizer, sigmoid activation\n",
            "Epoch 1/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.7389 - loss: 0.8413 - val_accuracy: 0.9318 - val_loss: 0.2226\n",
            "Epoch 2/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.9403 - loss: 0.1974 - val_accuracy: 0.9523 - val_loss: 0.1573\n",
            "Epoch 3/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.9584 - loss: 0.1431 - val_accuracy: 0.9675 - val_loss: 0.1105\n",
            "Training with: 3 epochs, 3 layers, 128 neurons, 32 batch size, sgd optimizer, relu activation\n",
            "Epoch 1/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.6622 - loss: 1.1731 - val_accuracy: 0.8975 - val_loss: 0.3517\n",
            "Epoch 2/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9108 - loss: 0.3060 - val_accuracy: 0.9227 - val_loss: 0.2601\n",
            "Epoch 3/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9291 - loss: 0.2442 - val_accuracy: 0.9393 - val_loss: 0.2059\n",
            "Training with: 3 epochs, 3 layers, 128 neurons, 32 batch size, sgd optimizer, sigmoid activation\n",
            "Epoch 1/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.1106 - loss: 2.3113 - val_accuracy: 0.1090 - val_loss: 2.2939\n",
            "Epoch 2/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.1307 - loss: 2.2904 - val_accuracy: 0.1225 - val_loss: 2.2759\n",
            "Epoch 3/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.2035 - loss: 2.2705 - val_accuracy: 0.1370 - val_loss: 2.2434\n",
            "Training with: 3 epochs, 3 layers, 128 neurons, 32 batch size, adam optimizer, relu activation\n",
            "Epoch 1/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8680 - loss: 0.4308 - val_accuracy: 0.9572 - val_loss: 0.1407\n",
            "Epoch 2/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9660 - loss: 0.1098 - val_accuracy: 0.9653 - val_loss: 0.1090\n",
            "Epoch 3/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9763 - loss: 0.0771 - val_accuracy: 0.9760 - val_loss: 0.0803\n",
            "Training with: 3 epochs, 3 layers, 128 neurons, 32 batch size, adam optimizer, sigmoid activation\n",
            "Epoch 1/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.7050 - loss: 0.9561 - val_accuracy: 0.9390 - val_loss: 0.2027\n",
            "Epoch 2/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9452 - loss: 0.1836 - val_accuracy: 0.9570 - val_loss: 0.1426\n",
            "Epoch 3/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9627 - loss: 0.1233 - val_accuracy: 0.9663 - val_loss: 0.1113\n",
            "Training with: 3 epochs, 3 layers, 128 neurons, 32 batch size, rmsprop optimizer, relu activation\n",
            "Epoch 1/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.8746 - loss: 0.4139 - val_accuracy: 0.9638 - val_loss: 0.1253\n",
            "Epoch 2/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9673 - loss: 0.1111 - val_accuracy: 0.9698 - val_loss: 0.1077\n",
            "Epoch 3/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9769 - loss: 0.0799 - val_accuracy: 0.9775 - val_loss: 0.0853\n",
            "Training with: 3 epochs, 3 layers, 128 neurons, 32 batch size, rmsprop optimizer, sigmoid activation\n",
            "Epoch 1/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.6704 - loss: 1.0498 - val_accuracy: 0.9258 - val_loss: 0.2501\n",
            "Epoch 2/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9305 - loss: 0.2300 - val_accuracy: 0.9533 - val_loss: 0.1558\n",
            "Epoch 3/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9541 - loss: 0.1540 - val_accuracy: 0.9472 - val_loss: 0.1719\n",
            "Training with: 3 epochs, 5 layers, 64 neurons, 16 batch size, sgd optimizer, relu activation\n",
            "Epoch 1/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.6494 - loss: 1.1075 - val_accuracy: 0.9225 - val_loss: 0.2517\n",
            "Epoch 2/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9283 - loss: 0.2372 - val_accuracy: 0.9472 - val_loss: 0.1721\n",
            "Epoch 3/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9507 - loss: 0.1638 - val_accuracy: 0.9550 - val_loss: 0.1410\n",
            "Training with: 3 epochs, 5 layers, 64 neurons, 16 batch size, sgd optimizer, sigmoid activation\n",
            "Epoch 1/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.1083 - loss: 2.3204 - val_accuracy: 0.1090 - val_loss: 2.3041\n",
            "Epoch 2/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.1095 - loss: 2.3035 - val_accuracy: 0.1055 - val_loss: 2.3023\n",
            "Epoch 3/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.1072 - loss: 2.3037 - val_accuracy: 0.1090 - val_loss: 2.3054\n",
            "Training with: 3 epochs, 5 layers, 64 neurons, 16 batch size, adam optimizer, relu activation\n",
            "Epoch 1/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.8448 - loss: 0.4857 - val_accuracy: 0.9540 - val_loss: 0.1512\n",
            "Epoch 2/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.9582 - loss: 0.1370 - val_accuracy: 0.9552 - val_loss: 0.1517\n",
            "Epoch 3/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.9678 - loss: 0.1045 - val_accuracy: 0.9625 - val_loss: 0.1178\n",
            "Training with: 3 epochs, 5 layers, 64 neurons, 16 batch size, adam optimizer, sigmoid activation\n",
            "Epoch 1/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.5038 - loss: 1.3782 - val_accuracy: 0.9198 - val_loss: 0.2985\n",
            "Epoch 2/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.9295 - loss: 0.2706 - val_accuracy: 0.9455 - val_loss: 0.1857\n",
            "Epoch 3/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.9526 - loss: 0.1743 - val_accuracy: 0.9563 - val_loss: 0.1553\n",
            "Training with: 3 epochs, 5 layers, 64 neurons, 16 batch size, rmsprop optimizer, relu activation\n",
            "Epoch 1/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.8545 - loss: 0.4673 - val_accuracy: 0.9540 - val_loss: 0.1522\n",
            "Epoch 2/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.9563 - loss: 0.1594 - val_accuracy: 0.9537 - val_loss: 0.1832\n",
            "Epoch 3/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9669 - loss: 0.1342 - val_accuracy: 0.9477 - val_loss: 0.2245\n",
            "Training with: 3 epochs, 5 layers, 64 neurons, 16 batch size, rmsprop optimizer, sigmoid activation\n",
            "Epoch 1/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.3264 - loss: 1.7725 - val_accuracy: 0.8515 - val_loss: 0.5234\n",
            "Epoch 2/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.8699 - loss: 0.4833 - val_accuracy: 0.9127 - val_loss: 0.3337\n",
            "Epoch 3/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.9114 - loss: 0.3371 - val_accuracy: 0.9148 - val_loss: 0.3025\n",
            "Training with: 3 epochs, 5 layers, 64 neurons, 32 batch size, sgd optimizer, relu activation\n",
            "Epoch 1/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.4107 - loss: 1.7466 - val_accuracy: 0.8913 - val_loss: 0.3795\n",
            "Epoch 2/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8944 - loss: 0.3574 - val_accuracy: 0.9247 - val_loss: 0.2545\n",
            "Epoch 3/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9279 - loss: 0.2432 - val_accuracy: 0.9415 - val_loss: 0.1996\n",
            "Training with: 3 epochs, 5 layers, 64 neurons, 32 batch size, sgd optimizer, sigmoid activation\n",
            "Epoch 1/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.1077 - loss: 2.3093 - val_accuracy: 0.1090 - val_loss: 2.3020\n",
            "Epoch 2/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.1138 - loss: 2.3019 - val_accuracy: 0.1053 - val_loss: 2.3025\n",
            "Epoch 3/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.1042 - loss: 2.3026 - val_accuracy: 0.1090 - val_loss: 2.3019\n",
            "Training with: 3 epochs, 5 layers, 64 neurons, 32 batch size, adam optimizer, relu activation\n",
            "Epoch 1/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.8266 - loss: 0.5526 - val_accuracy: 0.9538 - val_loss: 0.1519\n",
            "Epoch 2/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9574 - loss: 0.1402 - val_accuracy: 0.9635 - val_loss: 0.1213\n",
            "Epoch 3/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9676 - loss: 0.1031 - val_accuracy: 0.9667 - val_loss: 0.1157\n",
            "Training with: 3 epochs, 5 layers, 64 neurons, 32 batch size, adam optimizer, sigmoid activation\n",
            "Epoch 1/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.4489 - loss: 1.5351 - val_accuracy: 0.8888 - val_loss: 0.4312\n",
            "Epoch 2/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8946 - loss: 0.3900 - val_accuracy: 0.9165 - val_loss: 0.3061\n",
            "Epoch 3/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9234 - loss: 0.2712 - val_accuracy: 0.9348 - val_loss: 0.2359\n",
            "Training with: 3 epochs, 5 layers, 64 neurons, 32 batch size, rmsprop optimizer, relu activation\n",
            "Epoch 1/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.8256 - loss: 0.5473 - val_accuracy: 0.9385 - val_loss: 0.2262\n",
            "Epoch 2/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9552 - loss: 0.1540 - val_accuracy: 0.9607 - val_loss: 0.1239\n",
            "Epoch 3/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9658 - loss: 0.1156 - val_accuracy: 0.9692 - val_loss: 0.1068\n",
            "Training with: 3 epochs, 5 layers, 64 neurons, 32 batch size, rmsprop optimizer, sigmoid activation\n",
            "Epoch 1/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.2351 - loss: 2.0127 - val_accuracy: 0.7653 - val_loss: 0.7456\n",
            "Epoch 2/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8212 - loss: 0.5993 - val_accuracy: 0.8767 - val_loss: 0.4138\n",
            "Epoch 3/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9146 - loss: 0.3195 - val_accuracy: 0.9333 - val_loss: 0.2477\n",
            "Training with: 3 epochs, 5 layers, 128 neurons, 16 batch size, sgd optimizer, relu activation\n",
            "Epoch 1/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.6457 - loss: 1.1338 - val_accuracy: 0.9303 - val_loss: 0.2323\n",
            "Epoch 2/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9349 - loss: 0.2208 - val_accuracy: 0.9598 - val_loss: 0.1437\n",
            "Epoch 3/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.9555 - loss: 0.1449 - val_accuracy: 0.9600 - val_loss: 0.1333\n",
            "Training with: 3 epochs, 5 layers, 128 neurons, 16 batch size, sgd optimizer, sigmoid activation\n",
            "Epoch 1/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.1050 - loss: 2.3105 - val_accuracy: 0.0918 - val_loss: 2.3077\n",
            "Epoch 2/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.1048 - loss: 2.3064 - val_accuracy: 0.1090 - val_loss: 2.3106\n",
            "Epoch 3/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.1061 - loss: 2.3054 - val_accuracy: 0.0967 - val_loss: 2.3074\n",
            "Training with: 3 epochs, 5 layers, 128 neurons, 16 batch size, adam optimizer, relu activation\n",
            "Epoch 1/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - accuracy: 0.8653 - loss: 0.4223 - val_accuracy: 0.9508 - val_loss: 0.1575\n",
            "Epoch 2/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.9626 - loss: 0.1308 - val_accuracy: 0.9578 - val_loss: 0.1564\n",
            "Epoch 3/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.9707 - loss: 0.1005 - val_accuracy: 0.9713 - val_loss: 0.0996\n",
            "Training with: 3 epochs, 5 layers, 128 neurons, 16 batch size, adam optimizer, sigmoid activation\n",
            "Epoch 1/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - accuracy: 0.6683 - loss: 0.9927 - val_accuracy: 0.9188 - val_loss: 0.2718\n",
            "Epoch 2/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9366 - loss: 0.2233 - val_accuracy: 0.9433 - val_loss: 0.1918\n",
            "Epoch 3/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9575 - loss: 0.1499 - val_accuracy: 0.9585 - val_loss: 0.1405\n",
            "Training with: 3 epochs, 5 layers, 128 neurons, 16 batch size, rmsprop optimizer, relu activation\n",
            "Epoch 1/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.8685 - loss: 0.4295 - val_accuracy: 0.9578 - val_loss: 0.1601\n",
            "Epoch 2/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.9599 - loss: 0.1640 - val_accuracy: 0.9538 - val_loss: 0.2188\n",
            "Epoch 3/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.9667 - loss: 0.1502 - val_accuracy: 0.9585 - val_loss: 0.1800\n",
            "Training with: 3 epochs, 5 layers, 128 neurons, 16 batch size, rmsprop optimizer, sigmoid activation\n",
            "Epoch 1/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.3489 - loss: 1.6968 - val_accuracy: 0.8792 - val_loss: 0.4293\n",
            "Epoch 2/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.8894 - loss: 0.3933 - val_accuracy: 0.9365 - val_loss: 0.2322\n",
            "Epoch 3/3\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9370 - loss: 0.2290 - val_accuracy: 0.9192 - val_loss: 0.2896\n",
            "Training with: 3 epochs, 5 layers, 128 neurons, 32 batch size, sgd optimizer, relu activation\n",
            "Epoch 1/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.6041 - loss: 1.3105 - val_accuracy: 0.8942 - val_loss: 0.3411\n",
            "Epoch 2/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9112 - loss: 0.2968 - val_accuracy: 0.9318 - val_loss: 0.2251\n",
            "Epoch 3/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9402 - loss: 0.2024 - val_accuracy: 0.9508 - val_loss: 0.1619\n",
            "Training with: 3 epochs, 5 layers, 128 neurons, 32 batch size, sgd optimizer, sigmoid activation\n",
            "Epoch 1/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.1060 - loss: 2.3117 - val_accuracy: 0.1053 - val_loss: 2.3031\n",
            "Epoch 2/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.1057 - loss: 2.3044 - val_accuracy: 0.0982 - val_loss: 2.3036\n",
            "Epoch 3/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.1073 - loss: 2.3036 - val_accuracy: 0.0982 - val_loss: 2.3070\n",
            "Training with: 3 epochs, 5 layers, 128 neurons, 32 batch size, adam optimizer, relu activation\n",
            "Epoch 1/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8627 - loss: 0.4441 - val_accuracy: 0.9457 - val_loss: 0.1783\n",
            "Epoch 2/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9637 - loss: 0.1209 - val_accuracy: 0.9652 - val_loss: 0.1207\n",
            "Epoch 3/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9748 - loss: 0.0835 - val_accuracy: 0.9705 - val_loss: 0.1048\n",
            "Training with: 3 epochs, 5 layers, 128 neurons, 32 batch size, adam optimizer, sigmoid activation\n",
            "Epoch 1/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.5442 - loss: 1.2527 - val_accuracy: 0.9063 - val_loss: 0.3480\n",
            "Epoch 2/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9263 - loss: 0.2726 - val_accuracy: 0.9467 - val_loss: 0.1884\n",
            "Epoch 3/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9502 - loss: 0.1788 - val_accuracy: 0.9555 - val_loss: 0.1565\n",
            "Training with: 3 epochs, 5 layers, 128 neurons, 32 batch size, rmsprop optimizer, relu activation\n",
            "Epoch 1/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8599 - loss: 0.4422 - val_accuracy: 0.9593 - val_loss: 0.1431\n",
            "Epoch 2/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9647 - loss: 0.1287 - val_accuracy: 0.9750 - val_loss: 0.0970\n",
            "Epoch 3/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9736 - loss: 0.0995 - val_accuracy: 0.9723 - val_loss: 0.1071\n",
            "Training with: 3 epochs, 5 layers, 128 neurons, 32 batch size, rmsprop optimizer, sigmoid activation\n",
            "Epoch 1/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.2625 - loss: 1.9404 - val_accuracy: 0.8030 - val_loss: 0.6368\n",
            "Epoch 2/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8608 - loss: 0.4857 - val_accuracy: 0.9208 - val_loss: 0.2730\n",
            "Epoch 3/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9233 - loss: 0.2761 - val_accuracy: 0.9360 - val_loss: 0.2382\n",
            "Training with: 5 epochs, 3 layers, 64 neurons, 16 batch size, sgd optimizer, relu activation\n",
            "Epoch 1/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.7202 - loss: 0.9496 - val_accuracy: 0.9085 - val_loss: 0.2993\n",
            "Epoch 2/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9256 - loss: 0.2564 - val_accuracy: 0.9443 - val_loss: 0.1973\n",
            "Epoch 3/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9439 - loss: 0.1898 - val_accuracy: 0.9500 - val_loss: 0.1690\n",
            "Epoch 4/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9522 - loss: 0.1595 - val_accuracy: 0.9560 - val_loss: 0.1519\n",
            "Epoch 5/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9618 - loss: 0.1313 - val_accuracy: 0.9582 - val_loss: 0.1328\n",
            "Training with: 5 epochs, 3 layers, 64 neurons, 16 batch size, sgd optimizer, sigmoid activation\n",
            "Epoch 1/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.1211 - loss: 2.3009 - val_accuracy: 0.1618 - val_loss: 2.2835\n",
            "Epoch 2/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.1917 - loss: 2.2690 - val_accuracy: 0.3993 - val_loss: 2.1867\n",
            "Epoch 3/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.4024 - loss: 2.0810 - val_accuracy: 0.5273 - val_loss: 1.5778\n",
            "Epoch 4/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.5844 - loss: 1.4123 - val_accuracy: 0.6862 - val_loss: 1.0226\n",
            "Epoch 5/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7095 - loss: 0.9538 - val_accuracy: 0.7562 - val_loss: 0.8053\n",
            "Training with: 5 epochs, 3 layers, 64 neurons, 16 batch size, adam optimizer, relu activation\n",
            "Epoch 1/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.8659 - loss: 0.4481 - val_accuracy: 0.9568 - val_loss: 0.1477\n",
            "Epoch 2/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.9612 - loss: 0.1255 - val_accuracy: 0.9655 - val_loss: 0.1116\n",
            "Epoch 3/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.9721 - loss: 0.0863 - val_accuracy: 0.9665 - val_loss: 0.1057\n",
            "Epoch 4/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.9776 - loss: 0.0698 - val_accuracy: 0.9742 - val_loss: 0.0892\n",
            "Epoch 5/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.9802 - loss: 0.0595 - val_accuracy: 0.9700 - val_loss: 0.0952\n",
            "Training with: 5 epochs, 3 layers, 64 neurons, 16 batch size, adam optimizer, sigmoid activation\n",
            "Epoch 1/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.7102 - loss: 0.9894 - val_accuracy: 0.9388 - val_loss: 0.2080\n",
            "Epoch 2/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - accuracy: 0.9425 - loss: 0.1956 - val_accuracy: 0.9573 - val_loss: 0.1444\n",
            "Epoch 3/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.9602 - loss: 0.1324 - val_accuracy: 0.9635 - val_loss: 0.1165\n",
            "Epoch 4/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9710 - loss: 0.0979 - val_accuracy: 0.9668 - val_loss: 0.1112\n",
            "Epoch 5/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9761 - loss: 0.0790 - val_accuracy: 0.9703 - val_loss: 0.1020\n",
            "Training with: 5 epochs, 3 layers, 64 neurons, 16 batch size, rmsprop optimizer, relu activation\n",
            "Epoch 1/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.8711 - loss: 0.4431 - val_accuracy: 0.9527 - val_loss: 0.1549\n",
            "Epoch 2/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9573 - loss: 0.1446 - val_accuracy: 0.9590 - val_loss: 0.1323\n",
            "Epoch 3/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9685 - loss: 0.1122 - val_accuracy: 0.9655 - val_loss: 0.1262\n",
            "Epoch 4/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9739 - loss: 0.0970 - val_accuracy: 0.9722 - val_loss: 0.1102\n",
            "Epoch 5/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9764 - loss: 0.0865 - val_accuracy: 0.9702 - val_loss: 0.1388\n",
            "Training with: 5 epochs, 3 layers, 64 neurons, 16 batch size, rmsprop optimizer, sigmoid activation\n",
            "Epoch 1/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.6744 - loss: 1.0695 - val_accuracy: 0.9260 - val_loss: 0.2550\n",
            "Epoch 2/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9313 - loss: 0.2296 - val_accuracy: 0.9485 - val_loss: 0.1666\n",
            "Epoch 3/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9519 - loss: 0.1607 - val_accuracy: 0.9583 - val_loss: 0.1375\n",
            "Epoch 4/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.9625 - loss: 0.1242 - val_accuracy: 0.9638 - val_loss: 0.1188\n",
            "Epoch 5/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9691 - loss: 0.1071 - val_accuracy: 0.9658 - val_loss: 0.1148\n",
            "Training with: 5 epochs, 3 layers, 64 neurons, 32 batch size, sgd optimizer, relu activation\n",
            "Epoch 1/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6102 - loss: 1.3289 - val_accuracy: 0.8997 - val_loss: 0.3463\n",
            "Epoch 2/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9093 - loss: 0.3164 - val_accuracy: 0.9200 - val_loss: 0.2626\n",
            "Epoch 3/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9244 - loss: 0.2593 - val_accuracy: 0.9337 - val_loss: 0.2216\n",
            "Epoch 4/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9388 - loss: 0.2114 - val_accuracy: 0.9442 - val_loss: 0.1909\n",
            "Epoch 5/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9458 - loss: 0.1904 - val_accuracy: 0.9468 - val_loss: 0.1740\n",
            "Training with: 5 epochs, 3 layers, 64 neurons, 32 batch size, sgd optimizer, sigmoid activation\n",
            "Epoch 1/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.1115 - loss: 2.3300 - val_accuracy: 0.1090 - val_loss: 2.2956\n",
            "Epoch 2/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.1282 - loss: 2.2937 - val_accuracy: 0.2137 - val_loss: 2.2863\n",
            "Epoch 3/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.1558 - loss: 2.2826 - val_accuracy: 0.1393 - val_loss: 2.2714\n",
            "Epoch 4/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.2171 - loss: 2.2635 - val_accuracy: 0.1983 - val_loss: 2.2370\n",
            "Epoch 5/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.3113 - loss: 2.2161 - val_accuracy: 0.3802 - val_loss: 2.1267\n",
            "Training with: 5 epochs, 3 layers, 64 neurons, 32 batch size, adam optimizer, relu activation\n",
            "Epoch 1/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.8426 - loss: 0.5135 - val_accuracy: 0.9543 - val_loss: 0.1511\n",
            "Epoch 2/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9605 - loss: 0.1308 - val_accuracy: 0.9665 - val_loss: 0.1048\n",
            "Epoch 3/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9712 - loss: 0.0927 - val_accuracy: 0.9702 - val_loss: 0.0994\n",
            "Epoch 4/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9768 - loss: 0.0728 - val_accuracy: 0.9650 - val_loss: 0.1176\n",
            "Epoch 5/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9822 - loss: 0.0582 - val_accuracy: 0.9750 - val_loss: 0.0827\n",
            "Training with: 5 epochs, 3 layers, 64 neurons, 32 batch size, adam optimizer, sigmoid activation\n",
            "Epoch 1/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.6429 - loss: 1.1929 - val_accuracy: 0.9220 - val_loss: 0.2745\n",
            "Epoch 2/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9337 - loss: 0.2372 - val_accuracy: 0.9480 - val_loss: 0.1735\n",
            "Epoch 3/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9560 - loss: 0.1561 - val_accuracy: 0.9572 - val_loss: 0.1433\n",
            "Epoch 4/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9655 - loss: 0.1222 - val_accuracy: 0.9618 - val_loss: 0.1201\n",
            "Epoch 5/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9717 - loss: 0.0981 - val_accuracy: 0.9678 - val_loss: 0.1083\n",
            "Training with: 5 epochs, 3 layers, 64 neurons, 32 batch size, rmsprop optimizer, relu activation\n",
            "Epoch 1/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8559 - loss: 0.4859 - val_accuracy: 0.9478 - val_loss: 0.1728\n",
            "Epoch 2/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9600 - loss: 0.1347 - val_accuracy: 0.9658 - val_loss: 0.1135\n",
            "Epoch 3/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9694 - loss: 0.0978 - val_accuracy: 0.9705 - val_loss: 0.1093\n",
            "Epoch 4/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9772 - loss: 0.0788 - val_accuracy: 0.9723 - val_loss: 0.0969\n",
            "Epoch 5/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9798 - loss: 0.0705 - val_accuracy: 0.9755 - val_loss: 0.0961\n",
            "Training with: 5 epochs, 3 layers, 64 neurons, 32 batch size, rmsprop optimizer, sigmoid activation\n",
            "Epoch 1/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.6106 - loss: 1.2654 - val_accuracy: 0.9170 - val_loss: 0.2920\n",
            "Epoch 2/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9221 - loss: 0.2655 - val_accuracy: 0.9425 - val_loss: 0.1962\n",
            "Epoch 3/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9458 - loss: 0.1829 - val_accuracy: 0.9548 - val_loss: 0.1516\n",
            "Epoch 4/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9575 - loss: 0.1410 - val_accuracy: 0.9602 - val_loss: 0.1300\n",
            "Epoch 5/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9667 - loss: 0.1107 - val_accuracy: 0.9647 - val_loss: 0.1155\n",
            "Training with: 5 epochs, 3 layers, 128 neurons, 16 batch size, sgd optimizer, relu activation\n",
            "Epoch 1/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.7530 - loss: 0.8844 - val_accuracy: 0.9308 - val_loss: 0.2444\n",
            "Epoch 2/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.9330 - loss: 0.2259 - val_accuracy: 0.9462 - val_loss: 0.1797\n",
            "Epoch 3/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.9530 - loss: 0.1621 - val_accuracy: 0.9573 - val_loss: 0.1422\n",
            "Epoch 4/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.9624 - loss: 0.1276 - val_accuracy: 0.9645 - val_loss: 0.1220\n",
            "Epoch 5/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.9688 - loss: 0.1075 - val_accuracy: 0.9638 - val_loss: 0.1157\n",
            "Training with: 5 epochs, 3 layers, 128 neurons, 16 batch size, sgd optimizer, sigmoid activation\n",
            "Epoch 1/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.1120 - loss: 2.3101 - val_accuracy: 0.1055 - val_loss: 2.2799\n",
            "Epoch 2/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.1924 - loss: 2.2615 - val_accuracy: 0.4093 - val_loss: 2.1407\n",
            "Epoch 3/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.4148 - loss: 1.9817 - val_accuracy: 0.5835 - val_loss: 1.3463\n",
            "Epoch 4/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.6301 - loss: 1.1904 - val_accuracy: 0.7052 - val_loss: 0.8750\n",
            "Epoch 5/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.7455 - loss: 0.8202 - val_accuracy: 0.8023 - val_loss: 0.6952\n",
            "Training with: 5 epochs, 3 layers, 128 neurons, 16 batch size, adam optimizer, relu activation\n",
            "Epoch 1/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - accuracy: 0.8861 - loss: 0.3736 - val_accuracy: 0.9617 - val_loss: 0.1220\n",
            "Epoch 2/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.9674 - loss: 0.1056 - val_accuracy: 0.9755 - val_loss: 0.0802\n",
            "Epoch 3/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - accuracy: 0.9782 - loss: 0.0691 - val_accuracy: 0.9742 - val_loss: 0.0797\n",
            "Epoch 4/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5ms/step - accuracy: 0.9824 - loss: 0.0546 - val_accuracy: 0.9755 - val_loss: 0.0828\n",
            "Epoch 5/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9852 - loss: 0.0459 - val_accuracy: 0.9793 - val_loss: 0.0762\n",
            "Training with: 5 epochs, 3 layers, 128 neurons, 16 batch size, adam optimizer, sigmoid activation\n",
            "Epoch 1/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - accuracy: 0.7596 - loss: 0.7968 - val_accuracy: 0.9520 - val_loss: 0.1673\n",
            "Epoch 2/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - accuracy: 0.9524 - loss: 0.1573 - val_accuracy: 0.9623 - val_loss: 0.1159\n",
            "Epoch 3/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9684 - loss: 0.1042 - val_accuracy: 0.9712 - val_loss: 0.0890\n",
            "Epoch 4/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.9768 - loss: 0.0746 - val_accuracy: 0.9728 - val_loss: 0.0858\n",
            "Epoch 5/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - accuracy: 0.9818 - loss: 0.0572 - val_accuracy: 0.9753 - val_loss: 0.0848\n",
            "Training with: 5 epochs, 3 layers, 128 neurons, 16 batch size, rmsprop optimizer, relu activation\n",
            "Epoch 1/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.8895 - loss: 0.3668 - val_accuracy: 0.9655 - val_loss: 0.1196\n",
            "Epoch 2/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - accuracy: 0.9682 - loss: 0.1190 - val_accuracy: 0.9712 - val_loss: 0.1122\n",
            "Epoch 3/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.9745 - loss: 0.1000 - val_accuracy: 0.9672 - val_loss: 0.1728\n",
            "Epoch 4/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.9776 - loss: 0.0947 - val_accuracy: 0.9733 - val_loss: 0.1541\n",
            "Epoch 5/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - accuracy: 0.9797 - loss: 0.0888 - val_accuracy: 0.9763 - val_loss: 0.1468\n",
            "Training with: 5 epochs, 3 layers, 128 neurons, 16 batch size, rmsprop optimizer, sigmoid activation\n",
            "Epoch 1/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - accuracy: 0.7185 - loss: 0.8766 - val_accuracy: 0.9292 - val_loss: 0.2288\n",
            "Epoch 2/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - accuracy: 0.9408 - loss: 0.1973 - val_accuracy: 0.9550 - val_loss: 0.1463\n",
            "Epoch 3/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - accuracy: 0.9589 - loss: 0.1394 - val_accuracy: 0.9648 - val_loss: 0.1173\n",
            "Epoch 4/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - accuracy: 0.9674 - loss: 0.1092 - val_accuracy: 0.9677 - val_loss: 0.1114\n",
            "Epoch 5/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - accuracy: 0.9749 - loss: 0.0876 - val_accuracy: 0.9668 - val_loss: 0.1164\n",
            "Training with: 5 epochs, 3 layers, 128 neurons, 32 batch size, sgd optimizer, relu activation\n",
            "Epoch 1/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.6549 - loss: 1.2537 - val_accuracy: 0.9058 - val_loss: 0.3268\n",
            "Epoch 2/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9072 - loss: 0.3220 - val_accuracy: 0.9290 - val_loss: 0.2548\n",
            "Epoch 3/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9285 - loss: 0.2452 - val_accuracy: 0.9362 - val_loss: 0.2124\n",
            "Epoch 4/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9421 - loss: 0.1988 - val_accuracy: 0.9515 - val_loss: 0.1730\n",
            "Epoch 5/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9525 - loss: 0.1672 - val_accuracy: 0.9523 - val_loss: 0.1599\n",
            "Training with: 5 epochs, 3 layers, 128 neurons, 32 batch size, sgd optimizer, sigmoid activation\n",
            "Epoch 1/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1105 - loss: 2.3100 - val_accuracy: 0.1653 - val_loss: 2.2927\n",
            "Epoch 2/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.1444 - loss: 2.2887 - val_accuracy: 0.1605 - val_loss: 2.2745\n",
            "Epoch 3/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1978 - loss: 2.2675 - val_accuracy: 0.2467 - val_loss: 2.2393\n",
            "Epoch 4/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.3311 - loss: 2.2174 - val_accuracy: 0.4507 - val_loss: 2.1181\n",
            "Epoch 5/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.4369 - loss: 2.0453 - val_accuracy: 0.4848 - val_loss: 1.7238\n",
            "Training with: 5 epochs, 3 layers, 128 neurons, 32 batch size, adam optimizer, relu activation\n",
            "Epoch 1/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.8775 - loss: 0.4170 - val_accuracy: 0.9563 - val_loss: 0.1513\n",
            "Epoch 2/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9672 - loss: 0.1046 - val_accuracy: 0.9680 - val_loss: 0.1022\n",
            "Epoch 3/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9781 - loss: 0.0728 - val_accuracy: 0.9700 - val_loss: 0.0932\n",
            "Epoch 4/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - accuracy: 0.9819 - loss: 0.0565 - val_accuracy: 0.9710 - val_loss: 0.0882\n",
            "Epoch 5/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9854 - loss: 0.0448 - val_accuracy: 0.9780 - val_loss: 0.0799\n",
            "Training with: 5 epochs, 3 layers, 128 neurons, 32 batch size, adam optimizer, sigmoid activation\n",
            "Epoch 1/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.7088 - loss: 0.9400 - val_accuracy: 0.9355 - val_loss: 0.2169\n",
            "Epoch 2/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9415 - loss: 0.1981 - val_accuracy: 0.9563 - val_loss: 0.1406\n",
            "Epoch 3/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9619 - loss: 0.1295 - val_accuracy: 0.9638 - val_loss: 0.1117\n",
            "Epoch 4/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9715 - loss: 0.0958 - val_accuracy: 0.9705 - val_loss: 0.0985\n",
            "Epoch 5/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9775 - loss: 0.0749 - val_accuracy: 0.9737 - val_loss: 0.0887\n",
            "Training with: 5 epochs, 3 layers, 128 neurons, 32 batch size, rmsprop optimizer, relu activation\n",
            "Epoch 1/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8789 - loss: 0.3981 - val_accuracy: 0.9273 - val_loss: 0.2202\n",
            "Epoch 2/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9669 - loss: 0.1133 - val_accuracy: 0.9735 - val_loss: 0.0954\n",
            "Epoch 3/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9751 - loss: 0.0842 - val_accuracy: 0.9745 - val_loss: 0.0971\n",
            "Epoch 4/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9799 - loss: 0.0653 - val_accuracy: 0.9728 - val_loss: 0.1259\n",
            "Epoch 5/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9839 - loss: 0.0549 - val_accuracy: 0.9762 - val_loss: 0.1134\n",
            "Training with: 5 epochs, 3 layers, 128 neurons, 32 batch size, rmsprop optimizer, sigmoid activation\n",
            "Epoch 1/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.6625 - loss: 1.0618 - val_accuracy: 0.9242 - val_loss: 0.2578\n",
            "Epoch 2/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9300 - loss: 0.2316 - val_accuracy: 0.9510 - val_loss: 0.1647\n",
            "Epoch 3/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9542 - loss: 0.1530 - val_accuracy: 0.9617 - val_loss: 0.1245\n",
            "Epoch 4/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9645 - loss: 0.1190 - val_accuracy: 0.9688 - val_loss: 0.1063\n",
            "Epoch 5/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9686 - loss: 0.1008 - val_accuracy: 0.9698 - val_loss: 0.0981\n",
            "Training with: 5 epochs, 5 layers, 64 neurons, 16 batch size, sgd optimizer, relu activation\n",
            "Epoch 1/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.6545 - loss: 1.1000 - val_accuracy: 0.9263 - val_loss: 0.2499\n",
            "Epoch 2/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9318 - loss: 0.2284 - val_accuracy: 0.9478 - val_loss: 0.1737\n",
            "Epoch 3/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9506 - loss: 0.1659 - val_accuracy: 0.9573 - val_loss: 0.1415\n",
            "Epoch 4/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9613 - loss: 0.1311 - val_accuracy: 0.9653 - val_loss: 0.1190\n",
            "Epoch 5/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9669 - loss: 0.1086 - val_accuracy: 0.9675 - val_loss: 0.1080\n",
            "Training with: 5 epochs, 5 layers, 64 neurons, 16 batch size, sgd optimizer, sigmoid activation\n",
            "Epoch 1/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.1063 - loss: 2.3154 - val_accuracy: 0.1090 - val_loss: 2.3021\n",
            "Epoch 2/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.1036 - loss: 2.3042 - val_accuracy: 0.1090 - val_loss: 2.3032\n",
            "Epoch 3/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.1044 - loss: 2.3041 - val_accuracy: 0.1090 - val_loss: 2.3028\n",
            "Epoch 4/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.1050 - loss: 2.3039 - val_accuracy: 0.1090 - val_loss: 2.3082\n",
            "Training with: 5 epochs, 5 layers, 64 neurons, 16 batch size, adam optimizer, relu activation\n",
            "Epoch 1/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.8500 - loss: 0.4715 - val_accuracy: 0.9508 - val_loss: 0.1626\n",
            "Epoch 2/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.9584 - loss: 0.1362 - val_accuracy: 0.9588 - val_loss: 0.1399\n",
            "Epoch 3/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.9692 - loss: 0.1035 - val_accuracy: 0.9607 - val_loss: 0.1252\n",
            "Epoch 4/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.9740 - loss: 0.0861 - val_accuracy: 0.9682 - val_loss: 0.1122\n",
            "Epoch 5/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.9775 - loss: 0.0712 - val_accuracy: 0.9707 - val_loss: 0.1110\n",
            "Training with: 5 epochs, 5 layers, 64 neurons, 16 batch size, adam optimizer, sigmoid activation\n",
            "Epoch 1/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.5173 - loss: 1.3525 - val_accuracy: 0.9033 - val_loss: 0.3743\n",
            "Epoch 2/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.9081 - loss: 0.3451 - val_accuracy: 0.9358 - val_loss: 0.2365\n",
            "Epoch 3/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.9415 - loss: 0.2180 - val_accuracy: 0.9470 - val_loss: 0.1900\n",
            "Epoch 4/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.9521 - loss: 0.1698 - val_accuracy: 0.9528 - val_loss: 0.1711\n",
            "Epoch 5/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.9613 - loss: 0.1370 - val_accuracy: 0.9582 - val_loss: 0.1479\n",
            "Training with: 5 epochs, 5 layers, 64 neurons, 16 batch size, rmsprop optimizer, relu activation\n",
            "Epoch 1/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.8547 - loss: 0.4631 - val_accuracy: 0.9498 - val_loss: 0.1667\n",
            "Epoch 2/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - accuracy: 0.9551 - loss: 0.1580 - val_accuracy: 0.9558 - val_loss: 0.1716\n",
            "Epoch 3/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.9647 - loss: 0.1378 - val_accuracy: 0.9615 - val_loss: 0.1816\n",
            "Epoch 4/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.9707 - loss: 0.1282 - val_accuracy: 0.9682 - val_loss: 0.1550\n",
            "Epoch 5/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.9706 - loss: 0.1239 - val_accuracy: 0.9715 - val_loss: 0.1506\n",
            "Training with: 5 epochs, 5 layers, 64 neurons, 16 batch size, rmsprop optimizer, sigmoid activation\n",
            "Epoch 1/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.3415 - loss: 1.7614 - val_accuracy: 0.8783 - val_loss: 0.4960\n",
            "Epoch 2/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.8871 - loss: 0.4364 - val_accuracy: 0.9195 - val_loss: 0.3151\n",
            "Epoch 3/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9250 - loss: 0.2811 - val_accuracy: 0.9330 - val_loss: 0.2453\n",
            "Epoch 4/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9431 - loss: 0.2099 - val_accuracy: 0.9425 - val_loss: 0.2134\n",
            "Epoch 5/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.9536 - loss: 0.1764 - val_accuracy: 0.9473 - val_loss: 0.1969\n",
            "Training with: 5 epochs, 5 layers, 64 neurons, 32 batch size, sgd optimizer, relu activation\n",
            "Epoch 1/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.4853 - loss: 1.5752 - val_accuracy: 0.9055 - val_loss: 0.3321\n",
            "Epoch 2/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9049 - loss: 0.3206 - val_accuracy: 0.8860 - val_loss: 0.3328\n",
            "Epoch 3/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9294 - loss: 0.2368 - val_accuracy: 0.9392 - val_loss: 0.2110\n",
            "Epoch 4/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9438 - loss: 0.1889 - val_accuracy: 0.9382 - val_loss: 0.2077\n",
            "Epoch 5/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9525 - loss: 0.1623 - val_accuracy: 0.9538 - val_loss: 0.1523\n",
            "Training with: 5 epochs, 5 layers, 64 neurons, 32 batch size, sgd optimizer, sigmoid activation\n",
            "Epoch 1/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.1055 - loss: 2.3204 - val_accuracy: 0.1090 - val_loss: 2.3019\n",
            "Epoch 2/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.1121 - loss: 2.3026 - val_accuracy: 0.1055 - val_loss: 2.3039\n",
            "Epoch 3/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.1099 - loss: 2.3027 - val_accuracy: 0.1090 - val_loss: 2.3034\n",
            "Epoch 4/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.1080 - loss: 2.3030 - val_accuracy: 0.1090 - val_loss: 2.3055\n",
            "Training with: 5 epochs, 5 layers, 64 neurons, 32 batch size, adam optimizer, relu activation\n",
            "Epoch 1/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8264 - loss: 0.5453 - val_accuracy: 0.9518 - val_loss: 0.1605\n",
            "Epoch 2/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9572 - loss: 0.1377 - val_accuracy: 0.9655 - val_loss: 0.1165\n",
            "Epoch 3/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9697 - loss: 0.1043 - val_accuracy: 0.9663 - val_loss: 0.1113\n",
            "Epoch 4/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9758 - loss: 0.0781 - val_accuracy: 0.9715 - val_loss: 0.0956\n",
            "Epoch 5/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9788 - loss: 0.0702 - val_accuracy: 0.9693 - val_loss: 0.1159\n",
            "Training with: 5 epochs, 5 layers, 64 neurons, 32 batch size, adam optimizer, sigmoid activation\n",
            "Epoch 1/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.4523 - loss: 1.5101 - val_accuracy: 0.8992 - val_loss: 0.4083\n",
            "Epoch 2/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9080 - loss: 0.3559 - val_accuracy: 0.9267 - val_loss: 0.2818\n",
            "Epoch 3/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9347 - loss: 0.2481 - val_accuracy: 0.9453 - val_loss: 0.2159\n",
            "Epoch 4/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9488 - loss: 0.1895 - val_accuracy: 0.9497 - val_loss: 0.1855\n",
            "Epoch 5/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9558 - loss: 0.1604 - val_accuracy: 0.9563 - val_loss: 0.1613\n",
            "Training with: 5 epochs, 5 layers, 64 neurons, 32 batch size, rmsprop optimizer, relu activation\n",
            "Epoch 1/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8271 - loss: 0.5343 - val_accuracy: 0.9435 - val_loss: 0.1794\n",
            "Epoch 2/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9577 - loss: 0.1448 - val_accuracy: 0.9598 - val_loss: 0.1357\n",
            "Epoch 3/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9662 - loss: 0.1144 - val_accuracy: 0.9665 - val_loss: 0.1191\n",
            "Epoch 4/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9740 - loss: 0.0935 - val_accuracy: 0.9727 - val_loss: 0.1082\n",
            "Epoch 5/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9754 - loss: 0.0858 - val_accuracy: 0.9742 - val_loss: 0.1100\n",
            "Training with: 5 epochs, 5 layers, 64 neurons, 32 batch size, rmsprop optimizer, sigmoid activation\n",
            "Epoch 1/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.2025 - loss: 2.0745 - val_accuracy: 0.7607 - val_loss: 0.7522\n",
            "Epoch 2/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.8246 - loss: 0.6241 - val_accuracy: 0.8998 - val_loss: 0.3906\n",
            "Epoch 3/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9051 - loss: 0.3676 - val_accuracy: 0.9090 - val_loss: 0.3329\n",
            "Epoch 4/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9245 - loss: 0.2888 - val_accuracy: 0.9345 - val_loss: 0.2542\n",
            "Epoch 5/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9364 - loss: 0.2367 - val_accuracy: 0.9432 - val_loss: 0.2083\n",
            "Training with: 5 epochs, 5 layers, 128 neurons, 16 batch size, sgd optimizer, relu activation\n",
            "Epoch 1/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.7026 - loss: 0.9985 - val_accuracy: 0.9345 - val_loss: 0.2192\n",
            "Epoch 2/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9375 - loss: 0.2090 - val_accuracy: 0.9538 - val_loss: 0.1583\n",
            "Epoch 3/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9578 - loss: 0.1437 - val_accuracy: 0.9618 - val_loss: 0.1286\n",
            "Epoch 4/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9685 - loss: 0.1060 - val_accuracy: 0.9642 - val_loss: 0.1120\n",
            "Epoch 5/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.9738 - loss: 0.0874 - val_accuracy: 0.9682 - val_loss: 0.1048\n",
            "Training with: 5 epochs, 5 layers, 128 neurons, 16 batch size, sgd optimizer, sigmoid activation\n",
            "Epoch 1/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.1043 - loss: 2.3094 - val_accuracy: 0.0967 - val_loss: 2.3060\n",
            "Epoch 2/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - accuracy: 0.1055 - loss: 2.3062 - val_accuracy: 0.0967 - val_loss: 2.3101\n",
            "Epoch 3/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.1028 - loss: 2.3063 - val_accuracy: 0.1090 - val_loss: 2.3067\n",
            "Epoch 4/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.1053 - loss: 2.3055 - val_accuracy: 0.0982 - val_loss: 2.3046\n",
            "Epoch 5/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - accuracy: 0.1071 - loss: 2.3053 - val_accuracy: 0.1090 - val_loss: 2.3065\n",
            "Training with: 5 epochs, 5 layers, 128 neurons, 16 batch size, adam optimizer, relu activation\n",
            "Epoch 1/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 7ms/step - accuracy: 0.8719 - loss: 0.4091 - val_accuracy: 0.9613 - val_loss: 0.1362\n",
            "Epoch 2/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - accuracy: 0.9634 - loss: 0.1280 - val_accuracy: 0.9657 - val_loss: 0.1196\n",
            "Epoch 3/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 7ms/step - accuracy: 0.9722 - loss: 0.0962 - val_accuracy: 0.9715 - val_loss: 0.1072\n",
            "Epoch 4/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 7ms/step - accuracy: 0.9784 - loss: 0.0749 - val_accuracy: 0.9655 - val_loss: 0.1212\n",
            "Epoch 5/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 7ms/step - accuracy: 0.9813 - loss: 0.0635 - val_accuracy: 0.9762 - val_loss: 0.0825\n",
            "Training with: 5 epochs, 5 layers, 128 neurons, 16 batch size, adam optimizer, sigmoid activation\n",
            "Epoch 1/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 7ms/step - accuracy: 0.6291 - loss: 1.0800 - val_accuracy: 0.9285 - val_loss: 0.2625\n",
            "Epoch 2/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - accuracy: 0.9380 - loss: 0.2262 - val_accuracy: 0.9555 - val_loss: 0.1496\n",
            "Epoch 3/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 7ms/step - accuracy: 0.9582 - loss: 0.1476 - val_accuracy: 0.9630 - val_loss: 0.1277\n",
            "Epoch 4/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 7ms/step - accuracy: 0.9677 - loss: 0.1103 - val_accuracy: 0.9688 - val_loss: 0.1073\n",
            "Epoch 5/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 6ms/step - accuracy: 0.9751 - loss: 0.0856 - val_accuracy: 0.9637 - val_loss: 0.1307\n",
            "Training with: 5 epochs, 5 layers, 128 neurons, 16 batch size, rmsprop optimizer, relu activation\n",
            "Epoch 1/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - accuracy: 0.8663 - loss: 0.4288 - val_accuracy: 0.9583 - val_loss: 0.1519\n",
            "Epoch 2/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.9594 - loss: 0.1607 - val_accuracy: 0.9595 - val_loss: 0.1940\n",
            "Epoch 3/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.9658 - loss: 0.1536 - val_accuracy: 0.9645 - val_loss: 0.1531\n",
            "Epoch 4/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - accuracy: 0.9709 - loss: 0.1394 - val_accuracy: 0.9593 - val_loss: 0.2218\n",
            "Training with: 5 epochs, 5 layers, 128 neurons, 16 batch size, rmsprop optimizer, sigmoid activation\n",
            "Epoch 1/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.4032 - loss: 1.5945 - val_accuracy: 0.8762 - val_loss: 0.4296\n",
            "Epoch 2/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - accuracy: 0.8964 - loss: 0.3865 - val_accuracy: 0.9370 - val_loss: 0.2144\n",
            "Epoch 3/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - accuracy: 0.9403 - loss: 0.2115 - val_accuracy: 0.9517 - val_loss: 0.1641\n",
            "Epoch 4/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.9563 - loss: 0.1582 - val_accuracy: 0.9593 - val_loss: 0.1373\n",
            "Epoch 5/5\n",
            "\u001b[1m3375/3375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - accuracy: 0.9627 - loss: 0.1316 - val_accuracy: 0.9663 - val_loss: 0.1291\n",
            "Training with: 5 epochs, 5 layers, 128 neurons, 32 batch size, sgd optimizer, relu activation\n",
            "Epoch 1/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.5671 - loss: 1.3943 - val_accuracy: 0.9078 - val_loss: 0.3039\n",
            "Epoch 2/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9142 - loss: 0.2877 - val_accuracy: 0.9335 - val_loss: 0.2171\n",
            "Epoch 3/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9378 - loss: 0.2053 - val_accuracy: 0.9387 - val_loss: 0.1926\n",
            "Epoch 4/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9516 - loss: 0.1621 - val_accuracy: 0.9618 - val_loss: 0.1373\n",
            "Epoch 5/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9616 - loss: 0.1312 - val_accuracy: 0.9585 - val_loss: 0.1406\n",
            "Training with: 5 epochs, 5 layers, 128 neurons, 32 batch size, sgd optimizer, sigmoid activation\n",
            "Epoch 1/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.1071 - loss: 2.3147 - val_accuracy: 0.1090 - val_loss: 2.3042\n",
            "Epoch 2/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.1053 - loss: 2.3039 - val_accuracy: 0.1090 - val_loss: 2.3034\n",
            "Epoch 3/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.1071 - loss: 2.3037 - val_accuracy: 0.1090 - val_loss: 2.3057\n",
            "Epoch 4/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.1084 - loss: 2.3037 - val_accuracy: 0.0953 - val_loss: 2.3043\n",
            "Epoch 5/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.1072 - loss: 2.3038 - val_accuracy: 0.0967 - val_loss: 2.3055\n",
            "Training with: 5 epochs, 5 layers, 128 neurons, 32 batch size, adam optimizer, relu activation\n",
            "Epoch 1/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - accuracy: 0.8620 - loss: 0.4560 - val_accuracy: 0.9587 - val_loss: 0.1346\n",
            "Epoch 2/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9646 - loss: 0.1204 - val_accuracy: 0.9700 - val_loss: 0.1111\n",
            "Epoch 3/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.9740 - loss: 0.0865 - val_accuracy: 0.9713 - val_loss: 0.0974\n",
            "Epoch 4/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.9794 - loss: 0.0705 - val_accuracy: 0.9788 - val_loss: 0.0792\n",
            "Epoch 5/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9838 - loss: 0.0535 - val_accuracy: 0.9732 - val_loss: 0.0934\n",
            "Training with: 5 epochs, 5 layers, 128 neurons, 32 batch size, adam optimizer, sigmoid activation\n",
            "Epoch 1/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - accuracy: 0.4871 - loss: 1.3297 - val_accuracy: 0.9127 - val_loss: 0.3172\n",
            "Epoch 2/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9220 - loss: 0.2810 - val_accuracy: 0.9425 - val_loss: 0.1977\n",
            "Epoch 3/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.9484 - loss: 0.1819 - val_accuracy: 0.9548 - val_loss: 0.1523\n",
            "Epoch 4/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9626 - loss: 0.1345 - val_accuracy: 0.9595 - val_loss: 0.1361\n",
            "Epoch 5/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9692 - loss: 0.1070 - val_accuracy: 0.9645 - val_loss: 0.1208\n",
            "Training with: 5 epochs, 5 layers, 128 neurons, 32 batch size, rmsprop optimizer, relu activation\n",
            "Epoch 1/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8585 - loss: 0.4478 - val_accuracy: 0.9578 - val_loss: 0.1426\n",
            "Epoch 2/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9626 - loss: 0.1271 - val_accuracy: 0.9720 - val_loss: 0.1018\n",
            "Epoch 3/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9732 - loss: 0.1014 - val_accuracy: 0.9680 - val_loss: 0.1173\n",
            "Epoch 4/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9781 - loss: 0.0840 - val_accuracy: 0.9755 - val_loss: 0.1131\n",
            "Epoch 5/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9798 - loss: 0.0799 - val_accuracy: 0.9672 - val_loss: 0.1669\n",
            "Training with: 5 epochs, 5 layers, 128 neurons, 32 batch size, rmsprop optimizer, sigmoid activation\n",
            "Epoch 1/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.2866 - loss: 1.8887 - val_accuracy: 0.7863 - val_loss: 0.6740\n",
            "Epoch 2/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8597 - loss: 0.4977 - val_accuracy: 0.9055 - val_loss: 0.3493\n",
            "Epoch 3/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9216 - loss: 0.2836 - val_accuracy: 0.9260 - val_loss: 0.2622\n",
            "Epoch 4/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9424 - loss: 0.2032 - val_accuracy: 0.9465 - val_loss: 0.1852\n",
            "Epoch 5/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9526 - loss: 0.1661 - val_accuracy: 0.9540 - val_loss: 0.1719\n",
            "Best model config: {'epochs': 5, 'num_layers': 3, 'neurons': 128, 'batch_size': 16, 'optimizer': 'adam', 'activation': 'relu'} with validation accuracy: 0.9793333411216736\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "test_loss, test_acc = best_model.evaluate(x_test, y_test, verbose=2)\n",
        "print(f\"Test accuracy: {test_acc}\")\n",
        "\n",
        "y_pred = np.argmax(best_model.predict(x_test), axis=1)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=range(10), yticklabels=range(10))\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "K3Pz-KlPymlk",
        "outputId": "1b6b5183-df2f-46e9-ea8b-d99d6039f992"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 - 1s - 2ms/step - accuracy: 0.9787 - loss: 0.0822\n",
            "Test accuracy: 0.9786999821662903\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "cross_entropy_loss = best_model.evaluate(x_test, y_test)\n",
        "\n",
        "print(f\"Cross-Entropy Loss: {cross_entropy_loss[0]}, Accuracy: {cross_entropy_loss[1]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Cy18Ngyc3oA",
        "outputId": "0088d8e3-135a-461b-e429-981f17aafdc0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9760 - loss: 0.0925\n",
            "Cross-Entropy Loss: 0.08218851685523987, Accuracy: 0.9786999821662903\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best model config: {'epochs': 5, 'num_layers': 3, 'neurons': 128, 'batch_size': 16, 'optimizer': 'adam', 'activation': 'relu'} with validation accuracy: 0.9793333411216736"
      ],
      "metadata": {
        "id": "7aLHhDavAZde"
      }
    }
  ]
}